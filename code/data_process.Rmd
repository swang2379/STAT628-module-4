---
title: "data process"
author: "chenyu jiang"
date: "2024-12-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list=ls())
```


```{r}
library(readr)
library(tidyverse)
library(dplyr)
library(tidytext)
library(ggplot2)
library(wordcloud)
library(tm)
library(text2vec)
library(proxy)
library(Matrix)

data <- read.csv("all_episodes.csv")
```


```{r}
clean_description <- function(desc) {
  desc <- tolower(desc) # 转换为小写
  desc <- str_remove_all(desc, "https?://\\S+|www\\.\\S+") # 删除网址
  desc <- str_remove_all(desc, "[^\\x00-\\x7F]") # 删除非英语字符（包括emoji和非ASCII）
  desc <- str_remove_all(desc, "[[:punct:]]") # 删除标点符号
  desc <- str_squish(desc) # 去除多余空格
  return(desc)
}

# 添加清洗后的列
data <- data %>%
  mutate(Description_clean = sapply(Description, clean_description))

write.csv(data,"clean version.csv")
```


```{r}
data_clean <- read.csv("clean version.csv")
```



```{r}
# 假设 episodename 是一个包含播客名字的向量
episodename <- data_clean$Episodename

# 创建文本矩阵
it <- itoken(episodename, 
             preprocessor = function(x) gsub("[0-9]", "", tolower(x)),  # 去除数字并转小写
             tokenizer = word_tokenizer)
vocabulary <- create_vocabulary(it)
vectorizer <- vocab_vectorizer(vocabulary)

# 计算TF-IDF矩阵
dtm <- create_dtm(it, vectorizer)
tfidf <- TfIdf$new()
tfidf_matrix <- tfidf$fit_transform(dtm)

# 获取每个名字的TF-IDF分数
tfidf_scores <- rowSums(tfidf_matrix)

# 将稀疏矩阵转换为常规矩阵
dense_matrix <- as.matrix(tfidf_matrix)

# 查看稠密矩阵
print(dense_matrix)

# 计算余弦相似度矩阵
similarity_matrix <- proxy::simil(dense_matrix, method = "cosine")
similarity_matrix <- as.matrix(similarity_matrix)
diag(similarity_matrix) <- 1
# 查看相似度矩阵
print(similarity_matrix)

avg_similarity <- rowMeans(similarity_matrix)

# 计算 special score
special_scores <- tfidf_scores / (1 + avg_similarity)

# 归一化到0-1之间（根据需要）
special_scores <- (special_scores - min(special_scores)) / (max(special_scores) - min(special_scores))

data_clean <- data_clean %>%
  mutate(Special_Score = special_scores)
```


```{r}
# 加载 Bing 情感词典
bing_lexicon <- get_sentiments("bing")

# 计算情感得分
sentiment_scores <- data_clean %>%
  # 按每一行展开，将句子分词
  unnest_tokens(word, Description_clean) %>%
  # 过滤出在 Bing 情感词典中的词
  inner_join(bing_lexicon, by = "word") %>%
  # 将正面词汇计为 +1，负面词汇计为 -1
  mutate(sentiment_score = ifelse(sentiment == "positive", 1, -1)) %>%
  # 按 episodename 汇总情感得分
  group_by(Episodename) %>%
  summarize(sentiment_score = sum(sentiment_score, na.rm = TRUE)) 


score_range <- max(abs(range(sentiment_scores$sentiment_score, na.rm = TRUE)))

# 映射到 [0, 1] 范围，0.5 为中性
sentiment_scores <- sentiment_scores %>%
  mutate(normalized_score = 0.5 + sentiment_score / (2 * score_range))


# 将结果加入到原始数据
data_clean <- data_clean %>%
  left_join(sentiment_scores, by = "Episodename")%>%
  # 替换 NA 的情感得分为中性值 0.5
  mutate(normalized_score = replace_na(normalized_score, 0.5))



```


```{r}
data_clean1 <- data_clean %>%
  select(Category,Showname,Episodename,Duration_ms,Special_Score,normalized_score)
write_rds(data_clean1,"data use in app.rds")
```







